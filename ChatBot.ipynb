{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"odGi7X0q8j6U","outputId":"4a4495e8-5cfa-4c58-d191-e31a5d4eb393","executionInfo":{"status":"ok","timestamp":1705679543253,"user_tz":-345,"elapsed":35583,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import sys\n","\n","if 'google.colab' in sys.modules:\n","  %tensorflow_version 2.x\n","import tensorflow as tf\n","\n","tf.random.set_seed(1234)\n","AUTO = tf.data.experimental.AUTOTUNE\n","\n","!pip install tensorflow-datasets==1.2.0\n","import tensorflow_datasets as tfds\n","\n","import os\n","import re\n","import numpy as np\n","from time import time\n","import matplotlib.pyplot as plt\n","\n","print(\"Tensorflow version {}\".format(tf.__version__))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n","Collecting tensorflow-datasets==1.2.0\n","  Downloading tensorflow_datasets-1.2.0-py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==1.2.0) (1.4.0)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==1.2.0) (23.2.0)\n","Collecting dill (from tensorflow-datasets==1.2.0)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==1.2.0) (0.18.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==1.2.0) (1.23.5)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==1.2.0) (2.3)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==1.2.0) (3.20.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==1.2.0) (5.9.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==1.2.0) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==1.2.0) (1.16.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==1.2.0) (1.14.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==1.2.0) (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==1.2.0) (4.66.1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==1.2.0) (1.14.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2023.11.17)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets==1.2.0) (1.62.0)\n","Installing collected packages: dill, tensorflow-datasets\n","  Attempting uninstall: tensorflow-datasets\n","    Found existing installation: tensorflow-datasets 4.9.4\n","    Uninstalling tensorflow-datasets-4.9.4:\n","      Successfully uninstalled tensorflow-datasets-4.9.4\n","Successfully installed dill-0.3.7 tensorflow-datasets-1.2.0\n","Tensorflow version 2.12.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t5fY13Mm8uGb","outputId":"779ee6cc-86ba-4774-e3be-92dd34112178","executionInfo":{"status":"ok","timestamp":1705679554679,"user_tz":-345,"elapsed":12102,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Running on TPU {}'.format(tpu.cluster_spec().as_dict()['worker']))\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","else:\n","    strategy = tf.distribute.get_strategy()\n","\n","print(\"REPLICAS: {}\".format(strategy.num_replicas_in_sync))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on TPU ['10.2.28.18:8470']\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"]},{"output_type":"stream","name":"stdout","text":["REPLICAS: 8\n"]}]},{"cell_type":"code","metadata":{"id":"9c8S4Vglag0B"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CXq-ML7Z9ZY-"},"source":["# Maximum sentence length\n","MAX_LENGTH = 60\n","\n","# Maximum number of samples to preprocess\n","MAX_SAMPLES = 50000\n","\n","# For tf.data.Dataset\n","BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n","BUFFER_SIZE = 30000\n","\n","# For Transformer\n","NUM_LAYERS = 2\n","D_MODEL = 512\n","NUM_HEADS = 16\n","UNITS = 512\n","DROPOUT = 0.1\n","\n","EPOCHS = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4dvbCAgUxMIH","colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"status":"error","timestamp":1705679637399,"user_tz":-345,"elapsed":82746,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}},"outputId":"e45d67cc-20ef-44e6-b8b0-e7fb7bf1e85c"},"source":["# Code to read csv file into Colaboratory:\n","'''\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-ee280af8a5b4>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Authenticate and create the PyDrive client.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mgauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_application_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output, project_id)\u001b[0m\n\u001b[1;32m    279\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_check_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CredentialType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_auth_ephem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m       _message.blocking_request(\n\u001b[0m\u001b[1;32m    282\u001b[0m           \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m           \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'auth_user_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"4kJ999Wfx-L_"},"source":["'''id = '1rrqbtyxQTTbuONa3_ORMmR6e8YIedOuD'"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SG6LZFH-beGw","executionInfo":{"status":"ok","timestamp":1705679705482,"user_tz":-345,"elapsed":55004,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}},"outputId":"17e83469-d742-49ac-ec30-578462a3b850"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"vLXMhPzcyVs_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6fe36e7c-6873-40f5-c186-1c38376aba61","executionInfo":{"status":"ok","timestamp":1705679736867,"user_tz":-345,"elapsed":2161,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["#downloaded = drive.CreateFile({'id':id})\n","#downloaded.GetContentFile('9L_dataset.json')\n","#df3 = pd.read_json('9L_dataset.json')\n","df3 = pd.read_csv('/content/drive/MyDrive/training datasets/transformer_dataset.csv')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-7-44fde053b1cf>:4: DtypeWarning: Columns (2,3,4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df3 = pd.read_csv('/content/drive/MyDrive/training datasets/transformer_dataset.csv')\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LHqbwobDyjtf","outputId":"fcdd4163-0529-4158-f5f7-75f8e20cd1a0","executionInfo":{"status":"ok","timestamp":1705679741342,"user_tz":-345,"elapsed":395,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["print(df3)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                  Messege  \\\n","0       I remember going to see the fireworks with my ...   \n","1       Was this a friend you were in love with_comma_...   \n","2                     This was a best friend. I miss her.   \n","3                                     Where has she gone?   \n","4                                      We no longer talk.   \n","...                                                   ...   \n","141606  My grandson's step-mother sends him to school ...   \n","141607  My boyfriend is in recovery from drug addictio...   \n","141608  The birth mother attempted suicide several tim...   \n","141609  I think adult life is making him depressed and...   \n","141610  I just took a job that requires me to travel f...   \n","\n","                                                    Reply Unnamed: 2  \\\n","0       Was this a friend you were in love with_comma_...        NaN   \n","1                     This was a best friend. I miss her.        NaN   \n","2                                     Where has she gone?        NaN   \n","3                                      We no longer talk.        NaN   \n","4       Oh was this something that happened because of...        NaN   \n","...                                                   ...        ...   \n","141606  <p>I'm sorry you have tension between you and ...        NaN   \n","141607  <p>The true answer is, \"no one can really say ...        NaN   \n","141608  <p>How do you help yourself to believe you req...        NaN   \n","141609                    <p>hmm this is a tough one!</p>        NaN   \n","141610                                                NaN        NaN   \n","\n","       Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6  \n","0             NaN        NaN        NaN        NaN  \n","1             NaN        NaN        NaN        NaN  \n","2             NaN        NaN        NaN        NaN  \n","3             NaN        NaN        NaN        NaN  \n","4             NaN        NaN        NaN        NaN  \n","...           ...        ...        ...        ...  \n","141606        NaN        NaN        NaN        NaN  \n","141607        NaN        NaN        NaN        NaN  \n","141608        NaN        NaN        NaN        NaN  \n","141609        NaN        NaN        NaN        NaN  \n","141610        NaN        NaN        NaN        NaN  \n","\n","[141611 rows x 7 columns]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"uQLAyfMpzMcg","outputId":"9b329f21-ca9c-4979-a7df-8460c4605345","executionInfo":{"status":"ok","timestamp":1705679749095,"user_tz":-345,"elapsed":408,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["df3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  Messege  \\\n","0       I remember going to see the fireworks with my ...   \n","1       Was this a friend you were in love with_comma_...   \n","2                     This was a best friend. I miss her.   \n","3                                     Where has she gone?   \n","4                                      We no longer talk.   \n","...                                                   ...   \n","141606  My grandson's step-mother sends him to school ...   \n","141607  My boyfriend is in recovery from drug addictio...   \n","141608  The birth mother attempted suicide several tim...   \n","141609  I think adult life is making him depressed and...   \n","141610  I just took a job that requires me to travel f...   \n","\n","                                                    Reply Unnamed: 2  \\\n","0       Was this a friend you were in love with_comma_...        NaN   \n","1                     This was a best friend. I miss her.        NaN   \n","2                                     Where has she gone?        NaN   \n","3                                      We no longer talk.        NaN   \n","4       Oh was this something that happened because of...        NaN   \n","...                                                   ...        ...   \n","141606  <p>I'm sorry you have tension between you and ...        NaN   \n","141607  <p>The true answer is, \"no one can really say ...        NaN   \n","141608  <p>How do you help yourself to believe you req...        NaN   \n","141609                    <p>hmm this is a tough one!</p>        NaN   \n","141610                                                NaN        NaN   \n","\n","       Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6  \n","0             NaN        NaN        NaN        NaN  \n","1             NaN        NaN        NaN        NaN  \n","2             NaN        NaN        NaN        NaN  \n","3             NaN        NaN        NaN        NaN  \n","4             NaN        NaN        NaN        NaN  \n","...           ...        ...        ...        ...  \n","141606        NaN        NaN        NaN        NaN  \n","141607        NaN        NaN        NaN        NaN  \n","141608        NaN        NaN        NaN        NaN  \n","141609        NaN        NaN        NaN        NaN  \n","141610        NaN        NaN        NaN        NaN  \n","\n","[141611 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-2bed4d8a-d951-4394-b733-d8855ec79fc0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Messege</th>\n","      <th>Reply</th>\n","      <th>Unnamed: 2</th>\n","      <th>Unnamed: 3</th>\n","      <th>Unnamed: 4</th>\n","      <th>Unnamed: 5</th>\n","      <th>Unnamed: 6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I remember going to see the fireworks with my ...</td>\n","      <td>Was this a friend you were in love with_comma_...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Was this a friend you were in love with_comma_...</td>\n","      <td>This was a best friend. I miss her.</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>This was a best friend. I miss her.</td>\n","      <td>Where has she gone?</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Where has she gone?</td>\n","      <td>We no longer talk.</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>We no longer talk.</td>\n","      <td>Oh was this something that happened because of...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>141606</th>\n","      <td>My grandson's step-mother sends him to school ...</td>\n","      <td>&lt;p&gt;I'm sorry you have tension between you and ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>141607</th>\n","      <td>My boyfriend is in recovery from drug addictio...</td>\n","      <td>&lt;p&gt;The true answer is, \"no one can really say ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>141608</th>\n","      <td>The birth mother attempted suicide several tim...</td>\n","      <td>&lt;p&gt;How do you help yourself to believe you req...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>141609</th>\n","      <td>I think adult life is making him depressed and...</td>\n","      <td>&lt;p&gt;hmm this is a tough one!&lt;/p&gt;</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>141610</th>\n","      <td>I just took a job that requires me to travel f...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>141611 rows × 7 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bed4d8a-d951-4394-b733-d8855ec79fc0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2bed4d8a-d951-4394-b733-d8855ec79fc0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2bed4d8a-d951-4394-b733-d8855ec79fc0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-210595f4-af7b-4857-9c4a-b83ce75c270c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-210595f4-af7b-4857-9c4a-b83ce75c270c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-210595f4-af7b-4857-9c4a-b83ce75c270c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_ca4acb83-388a-45cd-bb24-46e3d62b6dbe\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df3')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_ca4acb83-388a-45cd-bb24-46e3d62b6dbe button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df3');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"M_ba0H3quRfI"},"source":["import re\n","def preprocess_sentence(sentence):\n","  sentence = sentence.lower().strip()\n","  # creating a space between a word and the punctuation following it\n","  # eg: \"he is a boy.\" => \"he is a boy .\"\n","  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n","  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n","  # removing contractions\n","  sentence = re.sub(r\"i'm\", \"i am\", sentence)\n","  sentence = re.sub(r\"he's\", \"he is\", sentence)\n","  sentence = re.sub(r\"she's\", \"she is\", sentence)\n","  sentence = re.sub(r\"it's\", \"it is\", sentence)\n","  sentence = re.sub(r\"that's\", \"that is\", sentence)\n","  sentence = re.sub(r\"what's\", \"that is\", sentence)\n","  sentence = re.sub(r\"where's\", \"where is\", sentence)\n","  sentence = re.sub(r\"how's\", \"how is\", sentence)\n","  sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n","  sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n","  sentence = re.sub(r\"\\'re\", \" are\", sentence)\n","  sentence = re.sub(r\"\\'d\", \" would\", sentence)\n","  sentence = re.sub(r\"\\'re\", \" are\", sentence)\n","  sentence = re.sub(r\"won't\", \"will not\", sentence)\n","  sentence = re.sub(r\"can't\", \"cannot\", sentence)\n","  sentence = re.sub(r\"n't\", \" not\", sentence)\n","  sentence = re.sub(r\"n'\", \"ng\", sentence)\n","  sentence = re.sub(r\"'bout\", \"about\", sentence)\n","  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n","  sentence = re.sub(r\"[^a-zA-Z?.!,0-9 %]+\", \" \", sentence)\n","  sentence = sentence.strip()\n","  return sentence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z378PQY-Cpnj"},"source":["questions = []\n","for i in df3.Messege:\n","  i = str(i)\n","  #i = preprocess_sentence(i)\n","  questions.append(i)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kPKdwhmIMEF6"},"source":["answers = []\n","for i in df3.Reply:\n","  i = str(i)\n","  #strings = i[(i.find(\"'answer'\")) + 11:i.find(\"}\")-1]\n","  #strings = preprocess_sentence(i)\n","  answers.append(i)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLCjH1tUQAh8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a0e95f34-abf6-478a-c78a-a3b3b81d4caa","executionInfo":{"status":"ok","timestamp":1705679812906,"user_tz":-345,"elapsed":6,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["print(questions[201])\n","print(\"\\n\")\n","print(answers[201])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["We just got back from vacation and our sleep times are off. It is really messing with me.\n","\n","\n","That will mess you up for a few days. The only thing I don't like about going away.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZOzoX6Yv7sF","outputId":"07e80403-484a-4b80-e81f-0ddd9e8c628c","executionInfo":{"status":"ok","timestamp":1705679838301,"user_tz":-345,"elapsed":403,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["print(df3.Messege[200])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I know it was rather sweet of them... i love anything asian! \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"svO04M3Vwm8H","outputId":"9e199b56-1c13-4077-e52a-8ed3eeb33141","executionInfo":{"status":"ok","timestamp":1705679845086,"user_tz":-345,"elapsed":445,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["preprocess_sentence('is 10,000 years old.')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'is 10 , 000 years old .'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HOawHG1axUi8","outputId":"527abe82-63b2-452f-b3bf-d23b71d4af03","executionInfo":{"status":"ok","timestamp":1705679855501,"user_tz":-345,"elapsed":389,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["print(df3.Reply[200])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["oh nice_comma_ im afraid the most asian food that i like is fortune cookies\n"]}]},{"cell_type":"code","metadata":{"id":"Blb-3gmoyIs2"},"source":["# Build tokenizer using tfds for both questions and answers\n","tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n","    questions + answers, target_vocab_size=20000)\n","\n","# Define start and end token to indicate the start and end of a sentence\n","START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n","\n","# Vocabulary size plus start and end token\n","VOCAB_SIZE = tokenizer.vocab_size + 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pxVXQE9m-HeB","outputId":"00522850-7175-49f8-a1a7-f7cee3d911d2","executionInfo":{"status":"ok","timestamp":1705680384451,"user_tz":-345,"elapsed":398,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["print('Tokenized sample question: {}'.format(tokenizer.encode(questions[20])))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized sample question: [269, 23, 90, 6, 465, 1906, 9, 60, 21, 565, 19523]\n"]}]},{"cell_type":"code","metadata":{"id":"QDmJ7uQBCwe-"},"source":["# Tokenize, filter and pad sentences\n","def tokenize_and_filter(inputs, outputs):\n","  tokenized_inputs, tokenized_outputs = [], []\n","\n","  for (sentence1, sentence2) in zip(inputs, outputs):\n","    # tokenize sentence\n","    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n","    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n","    # check tokenized sentence max length\n","    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n","      tokenized_inputs.append(sentence1)\n","      tokenized_outputs.append(sentence2)\n","\n","  # pad tokenized sentences\n","  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n","      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n","  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n","      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n","\n","  return tokenized_inputs, tokenized_outputs\n","\n","\n","questions, answers = tokenize_and_filter(questions, answers)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MN5bgFFNC6N2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"125c33f8-c32b-4d5c-a955-cb50d3b23b81","executionInfo":{"status":"ok","timestamp":1705680546803,"user_tz":-345,"elapsed":17,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["print('Vocab size: {}'.format(VOCAB_SIZE))\n","print('Number of samples: {}'.format(len(questions)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocab size: 19735\n","Number of samples: 136364\n"]}]},{"cell_type":"code","metadata":{"id":"3h8rfvrzEaKw"},"source":["# decoder inputs use the previous target as input\n","# remove START_TOKEN from targets\n","dataset = tf.data.Dataset.from_tensor_slices((\n","    {\n","        'inputs': questions,\n","        'dec_inputs': answers[:, :-1]\n","    },\n","    {\n","        'outputs': answers[:, 1:]\n","    },\n","))\n","\n","dataset = dataset.cache()\n","dataset = dataset.shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE)\n","dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oLtxJFgr_Ar6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c22336e0-9458-46d0-c4bd-466287b3d804","executionInfo":{"status":"ok","timestamp":1705680548321,"user_tz":-345,"elapsed":54,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["print(dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<_PrefetchDataset element_spec=({'inputs': TensorSpec(shape=(None, 60), dtype=tf.int32, name=None), 'dec_inputs': TensorSpec(shape=(None, 59), dtype=tf.int32, name=None)}, {'outputs': TensorSpec(shape=(None, 59), dtype=tf.int32, name=None)})>\n"]}]},{"cell_type":"code","metadata":{"id":"yeHpvoe2Kbp_"},"source":["def scaled_dot_product_attention(query, key, value, mask):\n","  \"\"\"Calculate the attention weights. \"\"\"\n","  matmul_qk = tf.matmul(query, key, transpose_b=True)\n","\n","  # scale matmul_qk\n","  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n","  logits = matmul_qk / tf.math.sqrt(depth)\n","\n","  # add the mask to zero out padding tokens\n","  if mask is not None:\n","    logits += (mask * -1e9)\n","\n","  # softmax is normalized on the last axis (seq_len_k)\n","  attention_weights = tf.nn.softmax(logits, axis=-1)\n","\n","  output = tf.matmul(attention_weights, value)\n","\n","  return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aQBdSuXfLNgS"},"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","\n","  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n","    super(MultiHeadAttention, self).__init__(name=name)\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","\n","    assert d_model % self.num_heads == 0\n","\n","    self.depth = d_model // self.num_heads\n","\n","    self.query_dense = tf.keras.layers.Dense(units=d_model)\n","    self.key_dense = tf.keras.layers.Dense(units=d_model)\n","    self.value_dense = tf.keras.layers.Dense(units=d_model)\n","\n","    self.dense = tf.keras.layers.Dense(units=d_model)\n","\n","  def get_config(self):\n","        config = super(MultiHeadAttention,self).get_config()\n","        config.update({\n","            'num_heads':self.num_heads,\n","            'd_model':self.d_model,\n","        })\n","        return config\n","\n","  def split_heads(self, inputs, batch_size):\n","    inputs = tf.keras.layers.Lambda(lambda inputs:tf.reshape(\n","        inputs, shape=(batch_size, -1, self.num_heads, self.depth)))(inputs)\n","    return tf.keras.layers.Lambda(lambda inputs: tf.transpose(inputs, perm=[0, 2, 1, 3]))(inputs)\n","\n","  def call(self, inputs):\n","    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n","        'value'], inputs['mask']\n","    batch_size = tf.shape(query)[0]\n","\n","    # linear layers\n","    query = self.query_dense(query)\n","    key = self.key_dense(key)\n","    value = self.value_dense(value)\n","\n","    # split heads\n","    query = self.split_heads(query, batch_size)\n","    key = self.split_heads(key, batch_size)\n","    value = self.split_heads(value, batch_size)\n","\n","    # scaled dot-product attention\n","    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n","    scaled_attention = tf.keras.layers.Lambda(lambda scaled_attention: tf.transpose(\n","        scaled_attention, perm=[0, 2, 1, 3]))(scaled_attention)\n","\n","    # concatenation of heads\n","    concat_attention = tf.keras.layers.Lambda(lambda scaled_attention: tf.reshape(scaled_attention,\n","                                  (batch_size, -1, self.d_model)))(scaled_attention)\n","\n","    # final linear layer\n","    outputs = self.dense(concat_attention)\n","\n","    return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9SWu3kXZMqD6"},"source":["def create_padding_mask(x):\n","  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n","  # (batch_size, 1, 1, sequence length)\n","  return mask[:, tf.newaxis, tf.newaxis, :]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tzjOFjJHM9GW","outputId":"26ff6185-9d9c-4260-f3c0-8b3b78739012","executionInfo":{"status":"ok","timestamp":1705680548323,"user_tz":-345,"elapsed":48,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[[[0. 0. 1. 0. 1.]]]\n","\n","\n"," [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"]}]},{"cell_type":"code","metadata":{"id":"mWbiziSGNAqV"},"source":["def create_look_ahead_mask(x):\n","  seq_len = tf.shape(x)[1]\n","  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n","  padding_mask = create_padding_mask(x)\n","  return tf.maximum(look_ahead_mask, padding_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wBcrLfhWNHxb","outputId":"9bbe6dca-a01c-494d-a68c-c09622854cb3","executionInfo":{"status":"ok","timestamp":1705680548324,"user_tz":-345,"elapsed":36,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[[[0. 1. 1. 1. 1.]\n","   [0. 0. 1. 1. 1.]\n","   [0. 0. 1. 1. 1.]\n","   [0. 0. 1. 0. 1.]\n","   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"]}]},{"cell_type":"code","metadata":{"id":"abftCf2VNJ8W"},"source":["class PositionalEncoding(tf.keras.layers.Layer):\n","\n","  def __init__(self, position, d_model):\n","    super(PositionalEncoding, self).__init__()\n","    self.pos_encoding = self.positional_encoding(position, d_model)\n","\n","  def get_config(self):\n","\n","        config = super(PositionalEncoding, self).get_config()\n","        config.update({\n","            'position': self.position,\n","            'd_model': self.d_model,\n","\n","        })\n","        return config\n","\n","  def get_angles(self, position, i, d_model):\n","    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n","    return position * angles\n","\n","  def positional_encoding(self, position, d_model):\n","    angle_rads = self.get_angles(\n","        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n","        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n","        d_model=d_model)\n","    # apply sin to even index in the array\n","    sines = tf.math.sin(angle_rads[:, 0::2])\n","    # apply cos to odd index in the array\n","    cosines = tf.math.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = tf.concat([sines, cosines], axis=-1)\n","    pos_encoding = pos_encoding[tf.newaxis, ...]\n","    return tf.cast(pos_encoding, tf.float32)\n","\n","  def call(self, inputs):\n","    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ZLWfiexNpet"},"source":["def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  attention = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention\")({\n","          'query': inputs,\n","          'key': inputs,\n","          'value': inputs,\n","          'mask': padding_mask\n","      })\n","  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n","  add_attention = tf.keras.layers.add([inputs,attention])\n","  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n","\n","  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  add_attention = tf.keras.layers.add([attention,outputs])\n","  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5UPbuhNROoWK"},"source":["def encoder(vocab_size,\n","            num_layers,\n","            units,\n","            d_model,\n","            num_heads,\n","            dropout,\n","            name=\"encoder\"):\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.keras.layers.Lambda(lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32)))(d_model)\n","  embeddings = PositionalEncoding(vocab_size,d_model)(embeddings)\n","\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  for i in range(num_layers):\n","    outputs = encoder_layer(\n","        units=units,\n","        d_model=d_model,\n","        num_heads=num_heads,\n","        dropout=dropout,\n","        name=\"encoder_layer_{}\".format(i),\n","    )([outputs, padding_mask])\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u9lSJLVaQQ7P"},"source":["def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n","  look_ahead_mask = tf.keras.Input(\n","      shape=(1, None, None), name=\"look_ahead_mask\")\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","  attention1 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_1\")(inputs={\n","          'query': inputs,\n","          'key': inputs,\n","          'value': inputs,\n","          'mask': look_ahead_mask\n","      })\n","  add_attention = tf.keras.layers.add([attention1,inputs])\n","  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n","\n","  attention2 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_2\")(inputs={\n","          'query': attention1,\n","          'key': enc_outputs,\n","          'value': enc_outputs,\n","          'mask': padding_mask\n","      })\n","  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n","  add_attention = tf.keras.layers.add([attention2,attention1])\n","  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n","\n","  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  add_attention = tf.keras.layers.add([outputs,attention2])\n","  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N-RV6cuaROi1"},"source":["def decoder(vocab_size,\n","            num_layers,\n","            units,\n","            d_model,\n","            num_heads,\n","            dropout,\n","            name='decoder'):\n","  inputs = tf.keras.Input(shape=(None,), name='inputs')\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n","  look_ahead_mask = tf.keras.Input(\n","      shape=(1, None, None), name='look_ahead_mask')\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.keras.layers.Lambda(lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32)))(d_model)\n","  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n","\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  for i in range(num_layers):\n","    outputs = decoder_layer(\n","        units=units,\n","        d_model=d_model,\n","        num_heads=num_heads,\n","        dropout=dropout,\n","        name='decoder_layer_{}'.format(i),\n","    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5qMl5RNPRkv6"},"source":["def transformer(vocab_size,\n","                num_layers,\n","                units,\n","                d_model,\n","                num_heads,\n","                dropout,\n","                name=\"transformer\"):\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n","\n","  enc_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='enc_padding_mask')(inputs)\n","  # mask the future tokens for decoder inputs at the 1st attention block\n","  look_ahead_mask = tf.keras.layers.Lambda(\n","      create_look_ahead_mask,\n","      output_shape=(1, None, None),\n","      name='look_ahead_mask')(dec_inputs)\n","  # mask the encoder outputs for the 2nd attention block\n","  dec_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='dec_padding_mask')(inputs)\n","\n","  enc_outputs = encoder(\n","      vocab_size=vocab_size,\n","      num_layers=num_layers,\n","      units=units,\n","      d_model=d_model,\n","      num_heads=num_heads,\n","      dropout=dropout,\n","  )(inputs=[inputs, enc_padding_mask])\n","\n","  dec_outputs = decoder(\n","      vocab_size=vocab_size,\n","      num_layers=num_layers,\n","      units=units,\n","      d_model=d_model,\n","      num_heads=num_heads,\n","      dropout=dropout,\n","  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n","\n","  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n","\n","  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sLzEQvsmRxGi"},"source":["def loss_function(y_true, y_pred):\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","\n","  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","      from_logits=True, reduction='none')(y_true, y_pred)\n","\n","  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n","  loss = tf.multiply(loss, mask)\n","\n","  return tf.reduce_mean(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJbmTuF5R5x8","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1705681471055,"user_tz":-345,"elapsed":386,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}},"outputId":"46a17712-90ba-4459-fa77-3ca0e0979288"},"source":["'''\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super(CustomSchedule, self).__init__()\n","\n","    self.d_model = tf.constant(d_model,dtype=tf.float32)\n","    self.warmup_steps = warmup_steps\n","\n","  def get_config(self):\n","        return {\"d_model\": self.d_model,\"warmup_steps\":self.warmup_steps}\n","\n","  def __call__(self, step):\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps**-1.5)\n","\n","    return tf.math.multiply(tf.math.rsqrt(self.d_model), tf.math.minimum(arg1, arg2))\n","    '''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nclass CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\\n\\n  def __init__(self, d_model, warmup_steps=4000):\\n    super(CustomSchedule, self).__init__()\\n    \\n    self.d_model = tf.constant(d_model,dtype=tf.float32)\\n    self.warmup_steps = warmup_steps\\n    \\n  def get_config(self):\\n        return {\"d_model\": self.d_model,\"warmup_steps\":self.warmup_steps}\\n    \\n  def __call__(self, step):\\n    arg1 = tf.math.rsqrt(step)\\n    arg2 = step * (self.warmup_steps**-1.5)\\n\\n    return tf.math.multiply(tf.math.rsqrt(self.d_model), tf.math.minimum(arg1, arg2))\\n    '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, d_model, warmup_steps=4000):\n","        super(CustomSchedule, self).__init__()\n","        self.d_model = tf.constant(d_model, dtype=tf.float32)\n","        self.warmup_steps = warmup_steps\n","\n","    def get_config(self):\n","        return {\"d_model\": self.d_model.numpy(), \"warmup_steps\": self.warmup_steps}\n","\n","    def __call__(self, step):\n","        arg1 = tf.math.rsqrt(tf.cast(step, tf.float32))\n","        arg2 = tf.cast(step, tf.float32) * (self.warmup_steps**-1.5)\n","\n","        return tf.math.multiply(tf.math.rsqrt(self.d_model), tf.math.minimum(arg1, arg2))\n"],"metadata":{"id":"weCSvKyIh19q"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58ALMw3XSIPp","outputId":"5e2869b7-4f4c-43d7-dd07-c42f1ce5a4cd","executionInfo":{"status":"ok","timestamp":1705681493866,"user_tz":-345,"elapsed":17502,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["# clear backend\n","tf.keras.backend.clear_session()\n","\n","learning_rate = CustomSchedule(D_MODEL)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","\n","def accuracy(y_true, y_pred):\n","  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n","\n","# initialize and compile model within strategy scope\n","with strategy.scope():\n","  model = transformer(\n","      vocab_size=VOCAB_SIZE,\n","      num_layers=NUM_LAYERS,\n","      units=UNITS,\n","      d_model=D_MODEL,\n","      num_heads=NUM_HEADS,\n","      dropout=DROPOUT)\n","\n","  model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"transformer\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," inputs (InputLayer)            [(None, None)]       0           []                               \n","                                                                                                  \n"," dec_inputs (InputLayer)        [(None, None)]       0           []                               \n","                                                                                                  \n"," enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n","                                                                                                  \n"," encoder (Functional)           (None, None, 512)    13260288    ['inputs[0][0]',                 \n","                                                                  'enc_padding_mask[0][0]']       \n","                                                                                                  \n"," look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n","                                e)                                                                \n","                                                                                                  \n"," dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n","                                                                                                  \n"," decoder (Functional)           (None, None, 512)    15363584    ['dec_inputs[0][0]',             \n","                                                                  'encoder[0][0]',                \n","                                                                  'look_ahead_mask[0][0]',        \n","                                                                  'dec_padding_mask[0][0]']       \n","                                                                                                  \n"," outputs (Dense)                (None, None, 19735)  10124055    ['decoder[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 38,747,927\n","Trainable params: 38,747,927\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"twfj6NbSSawD","outputId":"526ae8f9-2ebd-4035-84a8-cef9f8629614","executionInfo":{"status":"error","timestamp":1705689530081,"user_tz":-345,"elapsed":4579950,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["model.fit(dataset, epochs=EPOCHS)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","533/533 [==============================] - 64s 120ms/step - loss: 0.1479 - accuracy: 0.2554\n","Epoch 2/100\n","533/533 [==============================] - 65s 122ms/step - loss: 0.1376 - accuracy: 0.2578\n","Epoch 3/100\n","533/533 [==============================] - 64s 120ms/step - loss: 0.1289 - accuracy: 0.2598\n","Epoch 4/100\n","533/533 [==============================] - 63s 118ms/step - loss: 0.1210 - accuracy: 0.2616\n","Epoch 5/100\n","533/533 [==============================] - 61s 115ms/step - loss: 0.1136 - accuracy: 0.2635\n","Epoch 6/100\n","533/533 [==============================] - 60s 113ms/step - loss: 0.1072 - accuracy: 0.2650\n","Epoch 7/100\n","533/533 [==============================] - 62s 116ms/step - loss: 0.1009 - accuracy: 0.2666\n","Epoch 8/100\n","533/533 [==============================] - 61s 115ms/step - loss: 0.0958 - accuracy: 0.2678\n","Epoch 9/100\n","533/533 [==============================] - 61s 115ms/step - loss: 0.0905 - accuracy: 0.2692\n","Epoch 10/100\n","533/533 [==============================] - 66s 124ms/step - loss: 0.0859 - accuracy: 0.2704\n","Epoch 11/100\n","533/533 [==============================] - 67s 126ms/step - loss: 0.0818 - accuracy: 0.2715\n","Epoch 12/100\n","533/533 [==============================] - 68s 127ms/step - loss: 0.0777 - accuracy: 0.2726\n","Epoch 13/100\n","533/533 [==============================] - 66s 124ms/step - loss: 0.0745 - accuracy: 0.2734\n","Epoch 14/100\n","533/533 [==============================] - 66s 123ms/step - loss: 0.0709 - accuracy: 0.2744\n","Epoch 15/100\n","533/533 [==============================] - 64s 121ms/step - loss: 0.0679 - accuracy: 0.2752\n","Epoch 16/100\n","533/533 [==============================] - 62s 115ms/step - loss: 0.0650 - accuracy: 0.2760\n","Epoch 17/100\n","533/533 [==============================] - 62s 116ms/step - loss: 0.0626 - accuracy: 0.2767\n","Epoch 18/100\n","533/533 [==============================] - 65s 122ms/step - loss: 0.0600 - accuracy: 0.2774\n","Epoch 19/100\n","533/533 [==============================] - 64s 120ms/step - loss: 0.0575 - accuracy: 0.2781\n","Epoch 20/100\n","533/533 [==============================] - 64s 120ms/step - loss: 0.0555 - accuracy: 0.2787\n","Epoch 21/100\n","533/533 [==============================] - 67s 125ms/step - loss: 0.0534 - accuracy: 0.2793\n","Epoch 22/100\n","533/533 [==============================] - 68s 127ms/step - loss: 0.0516 - accuracy: 0.2798\n","Epoch 23/100\n","533/533 [==============================] - 65s 122ms/step - loss: 0.0499 - accuracy: 0.2803\n","Epoch 24/100\n","533/533 [==============================] - 65s 123ms/step - loss: 0.0480 - accuracy: 0.2808\n","Epoch 25/100\n","533/533 [==============================] - 64s 120ms/step - loss: 0.0463 - accuracy: 0.2813\n","Epoch 26/100\n","533/533 [==============================] - 64s 119ms/step - loss: 0.0448 - accuracy: 0.2818\n","Epoch 27/100\n","533/533 [==============================] - 65s 121ms/step - loss: 0.0436 - accuracy: 0.2821\n","Epoch 28/100\n","533/533 [==============================] - 61s 115ms/step - loss: 0.0424 - accuracy: 0.2825\n","Epoch 29/100\n","533/533 [==============================] - 66s 124ms/step - loss: 0.0410 - accuracy: 0.2829\n","Epoch 30/100\n","533/533 [==============================] - 62s 115ms/step - loss: 0.0399 - accuracy: 0.2832\n","Epoch 31/100\n","533/533 [==============================] - 62s 116ms/step - loss: 0.0387 - accuracy: 0.2836\n","Epoch 32/100\n","533/533 [==============================] - 61s 115ms/step - loss: 0.0378 - accuracy: 0.2839\n","Epoch 33/100\n","533/533 [==============================] - 62s 116ms/step - loss: 0.0368 - accuracy: 0.2842\n","Epoch 34/100\n","533/533 [==============================] - 62s 117ms/step - loss: 0.0357 - accuracy: 0.2845\n","Epoch 35/100\n","533/533 [==============================] - 67s 126ms/step - loss: 0.0348 - accuracy: 0.2847\n","Epoch 36/100\n","533/533 [==============================] - 65s 122ms/step - loss: 0.0340 - accuracy: 0.2850\n","Epoch 37/100\n","533/533 [==============================] - 65s 121ms/step - loss: 0.0330 - accuracy: 0.2853\n","Epoch 38/100\n","533/533 [==============================] - 67s 126ms/step - loss: 0.0322 - accuracy: 0.2855\n","Epoch 39/100\n","533/533 [==============================] - 66s 124ms/step - loss: 0.0314 - accuracy: 0.2858\n","Epoch 40/100\n","533/533 [==============================] - 66s 124ms/step - loss: 0.0308 - accuracy: 0.2860\n","Epoch 41/100\n","533/533 [==============================] - 66s 124ms/step - loss: 0.0300 - accuracy: 0.2862\n","Epoch 42/100\n","533/533 [==============================] - 67s 126ms/step - loss: 0.0293 - accuracy: 0.2864\n","Epoch 43/100\n","533/533 [==============================] - 65s 122ms/step - loss: 0.0287 - accuracy: 0.2866\n","Epoch 44/100\n","533/533 [==============================] - 64s 120ms/step - loss: 0.0281 - accuracy: 0.2868\n","Epoch 45/100\n","533/533 [==============================] - 65s 122ms/step - loss: 0.0276 - accuracy: 0.2869\n","Epoch 46/100\n","533/533 [==============================] - 62s 116ms/step - loss: 0.0269 - accuracy: 0.2872\n","Epoch 47/100\n","533/533 [==============================] - 64s 120ms/step - loss: 0.0265 - accuracy: 0.2872\n","Epoch 48/100\n","533/533 [==============================] - 62s 117ms/step - loss: 0.0260 - accuracy: 0.2874\n","Epoch 49/100\n","533/533 [==============================] - 64s 120ms/step - loss: 0.0256 - accuracy: 0.2875\n","Epoch 50/100\n","533/533 [==============================] - 65s 122ms/step - loss: 0.0248 - accuracy: 0.2878\n","Epoch 51/100\n","533/533 [==============================] - 65s 122ms/step - loss: 0.0245 - accuracy: 0.2879\n","Epoch 52/100\n","533/533 [==============================] - 66s 125ms/step - loss: 0.0239 - accuracy: 0.2881\n","Epoch 53/100\n","533/533 [==============================] - 66s 124ms/step - loss: 0.0237 - accuracy: 0.2881\n","Epoch 54/100\n","533/533 [==============================] - 63s 118ms/step - loss: 0.0233 - accuracy: 0.2883\n","Epoch 55/100\n","533/533 [==============================] - 66s 123ms/step - loss: 0.0228 - accuracy: 0.2884\n","Epoch 56/100\n","533/533 [==============================] - 63s 119ms/step - loss: 0.0223 - accuracy: 0.2885\n","Epoch 57/100\n","533/533 [==============================] - 62s 116ms/step - loss: 0.0220 - accuracy: 0.2886\n","Epoch 58/100\n","533/533 [==============================] - 62s 117ms/step - loss: 0.0215 - accuracy: 0.2888\n","Epoch 59/100\n","533/533 [==============================] - 62s 117ms/step - loss: 0.0213 - accuracy: 0.2889\n","Epoch 60/100\n","533/533 [==============================] - 62s 117ms/step - loss: 0.0209 - accuracy: 0.2890\n","Epoch 61/100\n","533/533 [==============================] - 63s 117ms/step - loss: 0.0206 - accuracy: 0.2891\n","Epoch 62/100\n","533/533 [==============================] - 65s 121ms/step - loss: 0.0202 - accuracy: 0.2892\n","Epoch 63/100\n","533/533 [==============================] - 65s 122ms/step - loss: 0.0199 - accuracy: 0.2893\n","Epoch 64/100\n","533/533 [==============================] - 61s 115ms/step - loss: 0.0195 - accuracy: 0.2894\n","Epoch 65/100\n","533/533 [==============================] - 63s 118ms/step - loss: 0.0193 - accuracy: 0.2895\n","Epoch 66/100\n","533/533 [==============================] - 64s 119ms/step - loss: 0.0190 - accuracy: 0.2896\n","Epoch 67/100\n","533/533 [==============================] - 64s 120ms/step - loss: 0.0188 - accuracy: 0.2896\n","Epoch 68/100\n","533/533 [==============================] - 64s 120ms/step - loss: 0.0184 - accuracy: 0.2898\n","Epoch 69/100\n","533/533 [==============================] - 65s 121ms/step - loss: 0.0181 - accuracy: 0.2899\n","Epoch 70/100\n","533/533 [==============================] - 67s 125ms/step - loss: 0.0178 - accuracy: 0.2899\n","Epoch 71/100\n","533/533 [==============================] - 67s 126ms/step - loss: 0.0177 - accuracy: 0.2900\n","Epoch 72/100\n","533/533 [==============================] - 68s 128ms/step - loss: 0.0176 - accuracy: 0.2900\n","Epoch 73/100\n","533/533 [==============================] - 68s 128ms/step - loss: 0.0171 - accuracy: 0.2901\n","Epoch 74/100\n","533/533 [==============================] - 69s 130ms/step - loss: 0.0170 - accuracy: 0.2902\n","Epoch 75/100\n","533/533 [==============================] - 67s 126ms/step - loss: 0.0167 - accuracy: 0.2903\n","Epoch 76/100\n","533/533 [==============================] - 64s 120ms/step - loss: 0.0166 - accuracy: 0.2902\n","Epoch 77/100\n","533/533 [==============================] - 65s 122ms/step - loss: 0.0162 - accuracy: 0.2904\n","Epoch 78/100\n","533/533 [==============================] - 65s 121ms/step - loss: 0.0161 - accuracy: 0.2905\n","Epoch 79/100\n","533/533 [==============================] - 65s 121ms/step - loss: 0.0159 - accuracy: 0.2905\n","Epoch 80/100\n","533/533 [==============================] - 63s 118ms/step - loss: 0.0157 - accuracy: 0.2906\n","Epoch 81/100\n","533/533 [==============================] - 64s 120ms/step - loss: 0.0155 - accuracy: 0.2906\n","Epoch 82/100\n","533/533 [==============================] - 64s 119ms/step - loss: 0.0153 - accuracy: 0.2907\n","Epoch 83/100\n","533/533 [==============================] - 63s 118ms/step - loss: 0.0152 - accuracy: 0.2907\n","Epoch 84/100\n","533/533 [==============================] - 65s 122ms/step - loss: 0.0149 - accuracy: 0.2908\n","Epoch 85/100\n","533/533 [==============================] - 69s 130ms/step - loss: 0.0147 - accuracy: 0.2909\n","Epoch 86/100\n","533/533 [==============================] - 67s 126ms/step - loss: 0.0146 - accuracy: 0.2909\n","Epoch 87/100\n","533/533 [==============================] - 65s 123ms/step - loss: 0.0145 - accuracy: 0.2909\n","Epoch 88/100\n","533/533 [==============================] - 67s 126ms/step - loss: 0.0142 - accuracy: 0.2910\n","Epoch 89/100\n","533/533 [==============================] - 66s 123ms/step - loss: 0.0141 - accuracy: 0.2911\n","Epoch 90/100\n","533/533 [==============================] - 64s 120ms/step - loss: 0.0139 - accuracy: 0.2911\n","Epoch 91/100\n","533/533 [==============================] - 67s 125ms/step - loss: 0.0138 - accuracy: 0.2911\n","Epoch 92/100\n","103/533 [====>.........................] - ETA: 52s - loss: 0.0254 - accuracy: 0.2629"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-89cd9a1a0817>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1692\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \"\"\"\n\u001b[1;32m   1159\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"uvKl9S45TXaa","executionInfo":{"status":"ok","timestamp":1707249122708,"user_tz":-345,"elapsed":4,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["def evaluate(sentence):\n","  START_TOKEN = '<start>'\n","  END_TOKEN = '<end>'\n","  sentence = preprocess_sentence(sentence)\n","\n","  sentence = tf.expand_dims(\n","      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n","\n","  output = tf.expand_dims(START_TOKEN, 0)\n","\n","  for i in range(MAX_LENGTH):\n","    predictions = model(inputs=[sentence, output], training=False)\n","\n","    # select the last word from the seq_len dimension\n","    predictions = predictions[:, -1:, :]\n","    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","\n","    # return the result if the predicted_id is equal to the end token\n","    if tf.equal(predicted_id, END_TOKEN[0]):\n","      break\n","\n","    # concatenated the predicted_id to the output which is given to the decoder\n","    # as its input.\n","    output = tf.concat([output, predicted_id], axis=-1)\n","\n","  return tf.squeeze(output, axis=0)\n","\n","\n","def predict(sentence):\n","  prediction = evaluate(sentence)\n","\n","  predicted_sentence = tokenizer.decode(\n","      [i for i in prediction if i < tokenizer.vocab_size])\n","\n","  print('Input: {}'.format(sentence))\n","  print('Output: {}'.format(predicted_sentence))\n","\n","  return predicted_sentence"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"oBs6WfxCtdN9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f7eb1a43-ca02-4b78-e8a7-5236a68c021a","executionInfo":{"status":"ok","timestamp":1705689550127,"user_tz":-345,"elapsed":13014,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["output = predict(\"hi, how are you?\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: hi, how are you?\n","Output: I am not sure yet. I was really nervous\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aQCUyVMdTf5-","outputId":"12988068-4b5c-4467-b60d-fdebe97bcd09","executionInfo":{"status":"ok","timestamp":1705689577645,"user_tz":-345,"elapsed":27520,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["output = predict(\"how are you doing?\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: how are you doing?\n","Output: I am doing well. I will be spending time on my birthday until we got the going.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nRkZ0HqAklVV","outputId":"c518ba07-90bc-49f5-df89-33b2856866af","executionInfo":{"status":"ok","timestamp":1705689587578,"user_tz":-345,"elapsed":9944,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["output = predict(\"Hi how are you doing today\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: Hi how are you doing today\n","Output: I recently had an argument with my sister. It made us both very annoyed.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4rDPSDckuec","outputId":"07e5cf9b-edc7-4b53-fbc7-a6b4424ab476","executionInfo":{"status":"ok","timestamp":1705689601204,"user_tz":-345,"elapsed":13641,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["output = predict(\"What happened for you to feel that way?\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: What happened for you to feel that way?\n","Output: I feel only guilty about it\\&undsccomma\\&undsc I think most people are going to throw up without their wife and sister.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kK1ZUJMckywV","outputId":"754466c1-2ab8-48ea-a313-c9c2cbbba09c","executionInfo":{"status":"ok","timestamp":1705689671490,"user_tz":-345,"elapsed":8644,"user":{"displayName":"Rahul kc","userId":"09147971769201536813"}}},"source":["output = predict(\"I am having nausea and headache. what should i do?\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: I am having nausea and headache. what should i do?\n","Output: Thanks for the kind words.  Hope it will definitely be Birthday\n"]}]}]}